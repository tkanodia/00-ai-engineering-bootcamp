{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cf924a",
   "metadata": {},
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e839a459",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tanyakanodia/learning-ai/00-ai-engineering-bootcamp-cohort-2/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import Prefetch, Filter, FieldCondition, MatchAny, FusionQuery, Document\n",
    "\n",
    "\n",
    "from langsmith import traceable, get_current_run_tree\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.types import Send, Command\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage, convert_to_openai_messages\n",
    "\n",
    "from jinja2 import Template\n",
    "from typing import Literal, Dict, Any, Annotated, List, Optional, Sequence\n",
    "from IPython.display import Image, display\n",
    "from operator import add\n",
    "from openai import OpenAI\n",
    "\n",
    "import openai\n",
    "\n",
    "import random\n",
    "import ast\n",
    "import inspect\n",
    "import instructor\n",
    "import json\n",
    "import numpy as np\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor, execute_batch\n",
    "\n",
    "from litellm import completion\n",
    "\n",
    "from utils.utils import get_tool_descriptions, format_ai_message\n",
    "from utils.tools import get_shopping_cart, add_to_shopping_cart, remove_from_cart, get_formatted_item_context, get_formatted_reviews_context, check_warehouse_availability, reserve_warehouse_items\n",
    "\n",
    "from langgraph.checkpoint.postgres import PostgresSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25efbb03",
   "metadata": {},
   "source": [
    "### Create a Coordinator Agent with LiteLLM Router and Feedback model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd0c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Delegation(BaseModel):\n",
    "    agent: str\n",
    "    task: str\n",
    "\n",
    "class CoordinatorAgentResponse(BaseModel):\n",
    "    next_agent: str\n",
    "    plan: List[Delegation]\n",
    "    final_answer: bool\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b4efc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coordinator_agent(state, models = [\"gpt-4.1-mini\", \"groq/llama-3.3-70b-versatile\"]):\n",
    "\n",
    "   prompt_template =  \"\"\"You are a Coordinator Agent as part of a shopping assistant.\n",
    "\n",
    "Your role is to create plans for solving user queries and delegate the tasks accordingly.\n",
    "You will be given a conversation history, your task is to create a plan for solving the user's query.\n",
    "After the plan is created, you should output the next agent to invoke and the task to be performed by that agent.\n",
    "Once an agent finishes its task, you will be handed the control back, you should then review the conversation history and revise the plan.\n",
    "If there is a sequence of tasks to be performed by a single agent, you should combine them into a single task.\n",
    "\n",
    "The possible agents are:\n",
    "\n",
    "- product_qa_agent: The user is asking a question about a product. This can be a question about available products, their specifications, user reviews etc.\n",
    "- shopping_cart_agent: The user is asking to add or remove items from the shopping cart or questions about the current shopping cart.\n",
    "\n",
    "CRITICAL RULES:\n",
    "- If next_agent is \"\", final_answer MUST be false\n",
    "(You cannot delegate the task to an agent and return to the user in the same response)\n",
    "- If final_answer is true, next_agent MUST be \"\"\n",
    "(You must wait for agent results before returning to user)\n",
    "- If you need to call other agents before answering, set:\n",
    "next_agent=\"...\", final_answer=false\n",
    "- After receiving agent results, you can then set:\n",
    "next_agent=\"\", final_answer=true\n",
    "- One of the following has to be true:\n",
    "next_agent is \"\" and final_answer is true\n",
    "next_agent is not \"\" and final_answer is false\n",
    "\n",
    "Additional instructions:\n",
    "\n",
    "- Do not route to any agent if the user's query needs clarification. Do it yourself.\n",
    "- Write the plan to the plan field.\n",
    "- Write the next agent to invoke to the next_agent field.\n",
    "- Once you have all the information needed to answer the user's query, you should set the final_answer field to True and output the answer to the user's query.\n",
    "- The final answer to the user query should be a comprehensive answer that explains the actions that were performed to answer the query.\n",
    "- Never set final_answer to true if the plan is not complete.\n",
    "- You should output the next_agent field as well as the plan field.\n",
    "\"\"\"\n",
    "\n",
    "   template = Template(prompt_template)\n",
    "   \n",
    "   prompt = template.render()\n",
    "\n",
    "   messages = state.messages\n",
    "\n",
    "   conversation = []\n",
    "\n",
    "   for message in messages:\n",
    "        conversation.append(convert_to_openai_messages(message))\n",
    "\n",
    "   client = instructor.from_litellm(completion)\n",
    "\n",
    "   for model in models:\n",
    "      try:\n",
    "         response, raw_response = client.chat.completions.create_with_completion(\n",
    "            model=model,\n",
    "            response_model=CoordinatorAgentResponse,\n",
    "            messages=[{\"role\": \"system\", \"content\": prompt}, *conversation],\n",
    "            temperature=0,\n",
    "         )\n",
    "         break\n",
    "      except Exception as e:\n",
    "         print(f\"Error with model {model}: {e}\")\n",
    "         continue\n",
    "\n",
    "   if response.final_answer:\n",
    "      ai_message = [AIMessage(\n",
    "         content=response.answer,\n",
    "      )]\n",
    "   else:\n",
    "      ai_message = []\n",
    "\n",
    "   return {\n",
    "      \"messages\": ai_message,\n",
    "      \"answer\": response.answer,\n",
    "      \"coordinator_agent\": {\n",
    "         \"iteration\": state.coordinator_agent.iteration + 1,\n",
    "         \"final_answer\": response.final_answer,\n",
    "         \"next_agent\": response.next_agent,\n",
    "         \"plan\": [data.model_dump() for data in response.plan]\n",
    "      }\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a660be3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCall(BaseModel):\n",
    "    name: str\n",
    "    arguments: dict\n",
    "\n",
    "class RAGUsedContext(BaseModel):\n",
    "    id: str = Field(description=\"ID of the item used to answer the question.\")\n",
    "    description: str = Field(description=\"Short description of the item used to answer the question.\")\n",
    "\n",
    "class AgentProperties(BaseModel):\n",
    "    iteration: int = 0\n",
    "    final_answer: bool = False\n",
    "    available_tools: List[Dict[str, Any]] = []\n",
    "    tool_calls: List[ToolCall] = []\n",
    "\n",
    "class CoordinatorAgentProperties(BaseModel):\n",
    "    iteration: int = 0\n",
    "    final_answer: bool = False\n",
    "    plan: List[Delegation] = []\n",
    "    next_agent: str = \"\"\n",
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[List[Any], add] = []\n",
    "    user_intent: str = \"\"\n",
    "    product_qa_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    shopping_cart_agent: AgentProperties = Field(default_factory=AgentProperties)\n",
    "    coordinator_agent: CoordinatorAgentProperties = Field(default_factory=AgentProperties)\n",
    "    answer: str = \"\"\n",
    "    references: Annotated[List[RAGUsedContext], add] = []\n",
    "    user_id: str = \"\"\n",
    "    cart_id: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "950576bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = State(\n",
    "    messages=[{\"role\": \"user\", \"content\": \"What is the weather today?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e4fb799",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = coordinator_agent(initial_state, models = [\"gpt-4.1-mini\", \"groq/llama-3.3-70b-versatile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3414d526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [],\n",
       " 'answer': 'I cannot provide weather information. Please specify if you need assistance with shopping or product-related queries.',\n",
       " 'coordinator_agent': {'iteration': 1,\n",
       "  'final_answer': False,\n",
       "  'next_agent': '',\n",
       "  'plan': []}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f578121",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = coordinator_agent(initial_state, models = [\"groq/llama-3.3-70b-versatile\", \"gpt-4.1-mini\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e567b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [],\n",
       " 'answer': 'I need to clarify the location to provide the weather.',\n",
       " 'coordinator_agent': {'iteration': 1,\n",
       "  'final_answer': False,\n",
       "  'next_agent': '',\n",
       "  'plan': [{'agent': 'CoordinatorAgent',\n",
       "    'task': 'Ask for location to provide the weather'}]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84114ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
